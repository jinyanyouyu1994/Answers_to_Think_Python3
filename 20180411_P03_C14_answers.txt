import sys
def test(did_pass):
    linenum = sys._getframe(1).f_lineno
    if did_pass:
        msg = "test at line {0} ok.".format(linenum)
    else:
        msg = "test at line {0} FAILED.".format(linenum)
    print(msg)

################

def search_linear(xs,target):
    for (i,v) in enumerate(xs):
        if v == target:
            return i
    return -1

friends = ["Joe", "Zoe", "Brad", "Angelina", "Zuki", "Thandi", "Paris"]

test(search_linear(friends, "Zoe") == 1)
test(search_linear(friends, "Joe") == 0)
test(search_linear(friends, "Paris") == 6)
test(search_linear(friends, "Bill") == -1)

####

vocab = ["apple", "boy", "dog", "down", "fell", "girl", "grass", "the", "tree"]
book_words = "the apple fell from the tree to the grass".split()
def find_unknown_words(vocab,wds):
    result = []
    for w in wds:
        if (search_linear(vocab,w) < 0):
            result.append(w)
    return result

test(find_unknown_words(vocab, book_words) == ["from", "to"])
test(find_unknown_words([], book_words) == book_words)
test(find_unknown_words(vocab, ["the", "boy", "fell"]) == [])

####

def load_words_from_file(filename):
    f = open(filename,"r")
    file_content = f.read()
    f.close()
    wds = file_content.split()
    return wds

bigger_vocab = load_words_from_file("vocab.txt")
print("There are {0} words in the vocab, starting with\n {1}".format(len(bigger_vocab),bigger_vocab[:6]))

###

def text_to_words(the_text):
    my_substitutions = the_text.maketrans(
        # if you find any of these
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\"#$%&()*+,-./:;<=>?@[]^_‘{|}~’\\",
        # replace them by these
        "abcdefghijklmnopqrstuvwxyz                                          ")
    cleaned_text = the_text.translate(my_substitutions)
    wds = cleaned_text.split()
    return wds

##################

def get_words_in_book(filename):
    f = open(filename,"r")
    content = f.read()
    f.close()
    wds = text_to_words(content)
    return wds

book_words = get_words_in_book("test.txt")
print("There are {0} words in the book, the first 100 are\n{1}".format(len(book_words),book_words[:100]))

missing_words = find_unknown_words(bigger_vocab,book_words)
print("There are {0} missing_words in the book".format(len(missing_words)))

############
import time
t0 = time.clock()
missing_words = find_unknown_words(bigger_vocab,book_words)
t1 = time.clock()
print("There are {0} missing_words in the book".format(len(missing_words)))
print("That took {0:.4f} seconds.".format(t1-t0))

#########
def search_binary(xs,target):
    for (i,v) in enumerate(xs):
        if v == target:
            return i
    return -1
	
#####
def search_binary(xs,target):
    lb = 0
    ub = len(xs)
    while True:
        if lb == ub:
            return -1
        mid_index = (lb + ub) // 2
        item_at_mid = xs[mid_index]
		#print("ROI[{0}:{1}(size = {2},probed = '{3}',target = '{4}'"
        # .format(lb,ub,ub-lb,item_at_mid,target))
        if item_at_mid == target:
            return item_at_mid
        if item_at_mid < target:
            lb = mid_index + 1
        else:
            ub = mid_index

################################################################################################################################################
################

def load_words_from_file(filename):
    f = open(filename,"r")
    file_content = f.read()
    f.close()
    wds = file_content.split()
    return wds

bigger_vocab = load_words_from_file("vocab.txt")
print("There are {0} words in the vocab, starting with\n {1}".format(len(bigger_vocab),bigger_vocab[:6]))

###

def text_to_words(the_text):
    my_substitutions = the_text.maketrans(
        # if you find any of these
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\"#$%&()*+,-./:;<=>?@[]^_‘{|}~’\\",
        # replace them by these
        "abcdefghijklmnopqrstuvwxyz                                          ")
    cleaned_text = the_text.translate(my_substitutions)
    wds = cleaned_text.split()
    return wds

##################

def get_words_in_book(filename):
    f = open(filename,"r")
    content = f.read()
    f.close()
    wds = text_to_words(content)
    return wds

book_words = get_words_in_book("test.txt")
print("There are {0} words in the book, the first 100 are\n{1}".format(len(book_words),book_words[:100]))
################

def search_linear(xs,target):
    for (i,v) in enumerate(xs):
        if v == target:
            return i
    return -1
##
def find_unknown_words(vocab,wds):
    result = []
    for w in wds:
        if (search_linear(vocab,w) < 0):
            result.append(w)
    return result
####
############
import time
t0 = time.clock()
missing_words = find_unknown_words(bigger_vocab,book_words)
t1 = time.clock()
print("There are {0} missing_words in the book".format(len(missing_words)))
print("That took {0:.4f} seconds.".format(t1-t0))

################################################################################################################################################
def remove_adjacent_dups(xs):
    result = []
    most_recent_elem = None
    for ele in xs:
        if ele != most_recent_elem:
            result.append(ele)
            most_recent_elem = ele
    return result

def text_to_words(the_text):
    my_substitutions = the_text.maketrans(
        # if you find any of these
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\"#$%&()*+,-./:;<=>?@[]^_‘{|}~’\\",
        # replace them by these
        "abcdefghijklmnopqrstuvwxyz                                          ")
    cleaned_text = the_text.translate(my_substitutions)
    wds = cleaned_text.split()
    return wds

def get_words_in_book(filename):
    f = open(filename,"r")
    content = f.read()
    f.close()
    wds = text_to_words(content)
    return wds

all_words = get_words_in_book("test.txt")
all_words.sort()
book_words = remove_adjacent_dups(all_words)
print("There are {0} words in the book. Only {1} are unique.".format(len(all_words),len(book_words)))
print("The first 100 words are \n{0}".format(book_words[:100]))

##### 

import sys
def test(did_pass):
    linenum = sys._getframe(1).f_lineno
    if did_pass:
        msg = "test at line {0} ok.".format(linenum)
    else:
        msg = "test at line {0} FAILED.".format(linenum)
    print(msg)

##this is simple and efficient for samll lists

def merge(xs,ys):
    zs = xs + ys
    zs.sort()
    return zs

test(merge([1,2,3], [3,4,5]) == [1,2,3,3,4,5])

### this is more quickly

def merge(xs,ys):
    result = []
    xi = 0
    yi = 0
    while True:
        if xi >= len(xs):
            result.extend(ys[yi:])
            return result
        if yi >= len(ys):
            result.extend(xs[xi:])
            return result
        if xs[xi] <= ys[yi]:
            result.append(xs[xi])
            xi += 1
        else:
            result.append(ys[yi])
            yi += 1

############################################################################################
import sys
def test(did_pass):
    linenum = sys._getframe(1).f_lineno
    if did_pass:
        msg = "test at line {0} ok.".format(linenum)
    else:
        msg = "test at line {0} FAILED.".format(linenum)
    print(msg)

def remove_adjacent_dups(xs):
    result = []
    most_recent_elem = None
    for ele in xs:
        if ele != most_recent_elem:
            result.append(ele)
            most_recent_elem = ele
    return result

def text_to_words(the_text):
    my_substitutions = the_text.maketrans(
        # if you find any of these
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\"#$%&()*+,-./:;<=>?@[]^_‘{|}~’\\",
        # replace them by these
        "abcdefghijklmnopqrstuvwxyz                                          ")
    cleaned_text = the_text.translate(my_substitutions)
    wds = cleaned_text.split()
    return wds

def get_words_in_book(filename):
    f = open(filename,"r")
    content = f.read()
    f.close()
    wds = text_to_words(content)
    return wds

def find_unknowns_merge_pattern(vocab,wds):
    result = []
    xi = 0
    yi = 0
    while True:
        if xi >= len(vocab):
            result.extend(wds[yi:])
            return result
        if yi >= len(wds):
            return result
        if vocab[xi] == wds[yi]:
            yi += 1
        elif vocab[xi] < wds[yi]:
            xi += 1
        else:
            result.append(wds[yi])
            yi += 1
all_words = get_words_in_book("test.txt")

def load_words_from_file(filename):
    f = open(filename,"r")
    file_content = f.read()
    f.close()
    wds = file_content.split()
    return wds

bigger_vocab = load_words_from_file("vocab.txt")
import time
t0 = time.clock()
all_words.sort()
book_words = remove_adjacent_dups(all_words)
missing_words = find_unknowns_merge_pattern(bigger_vocab, book_words)
t1 = time.clock()
print("There are {0} unknown words.".format(len(missing_words)))
print("That took {0:.4f} seconds.".format(t1-t0))
##########################################################################

### Eight Queens' Puzzle, I

def share_diagonal(x0,y0,x1,y1):
    dy = abs(y1-y0)
    dx = abs(x1-x0)
    return dx == dy

def col_clashes(bs,c):
    for i in range(c):
        if share_diagonal(i,bs[i],c,bs[c]):
            return True
    return False

def has_clashes(the_board):
    for col in range(1,len(the_board)):
        if col_clashes(the_board,col):
            return True
    return False

###Eight Queens' Puzzle, II

def main():
    import random
    rng = random.Random()

    bd = list(range(8))
    num_found = 0
    tries = 0
    while num_found <10:
        rng.shuffle(bd)
        tries += 1
        if not has_clashes(bd):
            print("Found solution {0} in {1} tries.".format(bd,tries))
            tries = 0
            num_found += 1
main()

### T1

import sys

def test(did_pass):
    linenum = sys._getframe(1).f_lineno
    if did_pass:
        msg = "test at line {0} ok.".format(linenum)
    else:
        msg = "test at line {0} FAILED.".format(linenum)
    print(msg)

def load_words_from_file(filename):
    f = open(filename,"r")
    file_content = f.read()
    f.close()
    wds = file_content.split()
    return wds

def text_to_words(the_text):
    my_substitutions = the_text.maketrans(
        # if you find any of these
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\"#$%&()*+,-./:;<=>?@[]^_‘{|}~’\\",
        # replace them by these
        "abcdefghijklmnopqrstuvwxyz                                          ")
    cleaned_text = the_text.translate(my_substitutions)
    wds = cleaned_text.split()
    return wds

def get_words_in_book(filename):
    f = open(filename,"r")
    content = f.read()
    f.close()
    wds = text_to_words(content)
    return wds

def remove_adjacent_dups(xs):
    result = []
    elem = None
    for ele in xs:
        if ele != elem:
            result.append(ele)
            elem = ele
    return result

def search_linear(xs,target):
    for (i,v) in enumerate(xs):
        if v == target:
            return i
    return -1

def find_diff_words(vocab,wds):
    result = []
    for w in wds:
        if (search_linear(vocab,w) < 0):
            result.append(w)
    return result

def find_same_words(vocab,wds):
    result = []
    for w in wds:
        if (search_linear(vocab,w) > 0):
            result.append(w)
    return result

def merge(xs,ys):
    result = []
    xi = 0
    yi = 0
    while True:
        if xi >= len(xs):
            result.extend(ys[yi:])
            return result
        if yi >= len(ys):
            result.extend(xs[xi:])
            return result
        if xs[xi] <= ys[yi]:
            result.append(xs[xi])
            xi += 1
        elif xs[xi] <= ys[yi] and  ys[yi] not in xs:
            result.append(ys[yi])
            yi += 1

vocab = load_words_from_file("vocab.txt")
vocab.sort()
print("There are {0} words in the book.".format(len(vocab)))
book_words = get_words_in_book("test.txt")
print("There are {0} words in the book.".format(len(book_words)))
book_words.sort()
no_dups_words = remove_adjacent_dups(book_words)
print("There are {0} words in the book. Only {1} are unique.".format(len(book_words),len(no_dups_words)))
same_words = find_same_words(vocab,no_dups_words)
print("There are {0} words in the book are same. There are {1}".format(len(same_words),same_words))
diff_words = find_diff_words(vocab,no_dups_words)
print("There are {0} words in the book are different.".format(len(diff_words)))
bagdiff = merge(no_dups_words,vocab)
print("There are {0} words in the book are merged.".format(len(bagdiff)))

### T2




